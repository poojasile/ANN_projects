{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d5c360-782d-407b-b897-df5547779d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 99.75%\n",
      "Validation Accuracy = 100.00%\n",
      "Test Accuracy = 100.00%\n"
     ]
    }
   ],
   "source": [
    "## perceptron \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Directory paths\n",
    "base_directory = '/home/pooja-sile/Desktop/2_folder/'\n",
    "train_directory = os.path.join(base_directory, 'Training')\n",
    "valid_directory = os.path.join(base_directory, 'Validation')\n",
    "test_directory = os.path.join(base_directory, 'Testing')\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "num_features = None\n",
    "weights = None\n",
    "bias = None\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training and evaluation in a single loop\n",
    "for epoch in range(epochs):\n",
    "    # Read training data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for filename in os.listdir(train_directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as per your images\n",
    "            file_path = os.path.join(train_directory, filename)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((100, 100)).convert('L')  # Resize and convert to grayscale ('L' mode)\n",
    "            img_array = np.array(img)\n",
    "            X_train.append(img_array.flatten())  # Flatten image into 1D array\n",
    "            # Assuming the label is encoded in the filename or directory structure\n",
    "            label = 1 if 'class1' in filename else 0  # Adjust based on your data\n",
    "            y_train.append(label)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Check if X_train is empty or has unexpected structure\n",
    "    if X_train.shape[0] == 0 or X_train.ndim != 2 or X_train.shape[1] < 1:\n",
    "        print(f\"Warning: X_train is empty or has unexpected structure in epoch {epoch + 1}. Skipping epoch.\")\n",
    "        continue\n",
    "    \n",
    "    # Initialize weights and bias on first epoch\n",
    "    if epoch == 0:\n",
    "        num_features = X_train.shape[1]\n",
    "        weights = np.zeros(num_features)\n",
    "        bias = 0.0\n",
    "    \n",
    "    # Read validation data\n",
    "    X_valid = []\n",
    "    y_valid = []\n",
    "    for filename in os.listdir(valid_directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as per your images\n",
    "            file_path = os.path.join(valid_directory, filename)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((100, 100)).convert('L')  # Resize and convert to grayscale ('L' mode)\n",
    "            img_array = np.array(img)\n",
    "            X_valid.append(img_array.flatten())  # Flatten image into 1D array\n",
    "            # Assuming the label is encoded in the filename or directory structure\n",
    "            label = 1 if 'class1' in filename else 0  # Adjust based on your data\n",
    "            y_valid.append(label)\n",
    "    X_valid = np.array(X_valid)\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    # Read test data\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for filename in os.listdir(test_directory):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as per your images\n",
    "            file_path = os.path.join(test_directory, filename)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((100, 100)).convert('L')  # Resize and convert to grayscale ('L' mode)\n",
    "            img_array = np.array(img)\n",
    "            X_test.append(img_array.flatten())  # Flatten image into 1D array\n",
    "            # Assuming the label is encoded in the filename or directory structure\n",
    "            label = 1 if 'class1' in filename else 0  # Adjust based on your data\n",
    "            y_test.append(label)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Training loop\n",
    "    correct_train = 0\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train[i]\n",
    "        y_true = y_train[i]\n",
    "        \n",
    "        # Predict\n",
    "        linear_output = np.dot(weights, x) + bias\n",
    "        y_pred = 1 if linear_output >= 0 else 0\n",
    "        \n",
    "        # Update weights and bias if prediction is incorrect\n",
    "        if y_true != y_pred:\n",
    "            if y_true == 1:\n",
    "                weights += learning_rate * x\n",
    "                bias += learning_rate\n",
    "            else:\n",
    "                weights -= learning_rate * x\n",
    "                bias -= learning_rate\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        if y_true == y_pred:\n",
    "            correct_train += 1\n",
    "    train_accuracy = correct_train / len(X_train)\n",
    "    print(f\"Train Accuracy = {train_accuracy:.2%}\")   \n",
    "    \n",
    "    # Validation accuracy\n",
    "    correct_valid = 0\n",
    "    for i in range(len(X_valid)):\n",
    "        x = X_valid[i]\n",
    "        y_true = y_valid[i]\n",
    "        linear_output = np.dot(weights, x) + bias\n",
    "        y_pred = 1 if linear_output >= 0 else 0\n",
    "        if y_true == y_pred:\n",
    "            correct_valid += 1\n",
    "    validation_accuracy = correct_valid / len(X_valid)\n",
    "    print(f\"Validation Accuracy = {validation_accuracy:.2%}\")\n",
    "\n",
    "    # Test accuracy\n",
    "    correct_test = 0\n",
    "    for i in range(len(X_test)):\n",
    "        x = X_test[i]\n",
    "        y_true = y_test[i]\n",
    "        linear_output = np.dot(weights, x) + bias\n",
    "        y_pred = 1 if linear_output >= 0 else 0\n",
    "        if y_true == y_pred:\n",
    "            correct_test += 1\n",
    "    test_accuracy = correct_test / len(X_test)\n",
    "    print(f\"Test Accuracy = {test_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdeb289-ef34-429b-b8ad-3dc9d533d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Accuracy: 1.00, Loss: 0.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "## simple neural network\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Paths to the folders\n",
    "base_directory = '/home/pooja-sile/Desktop/2_folder/'\n",
    "train_directory = os.path.join(base_directory, 'Training')\n",
    "valid_directory = os.path.join(base_directory, 'Validation')\n",
    "test_directory = os.path.join(base_directory, 'Testing')\n",
    "\n",
    "# Load training data\n",
    "X_train, y_train = [], []\n",
    "for file in os.listdir(train_directory):\n",
    "    img_path = os.path.join(train_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_train.append(img)\n",
    "        y_train.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Initialize weights and bias\n",
    "weights = np.random.rand(X_train.shape[1])\n",
    "bias = 0\n",
    "\n",
    "# Set learning rate and number of iterations\n",
    "learning_rate = 0.01\n",
    "n_iters = 1\n",
    "\n",
    "# Train the model\n",
    "for _ in range(n_iters):\n",
    "    for i in range(len(X_train)):\n",
    "        x_i = X_train[i]\n",
    "        y_i = y_train[i]\n",
    "        # Calculate the predicted output\n",
    "        predicted = np.where(np.dot(x_i, weights) + bias >= 0, 1, -1)\n",
    "        # Update weights and bias\n",
    "        update = learning_rate * (y_i - predicted)\n",
    "        weights += update * x_i\n",
    "        bias += update\n",
    "    \n",
    "    # Calculate accuracy and loss\n",
    "    predictions = np.where(np.dot(X_train, weights) + bias >= 0, 1, -1)\n",
    "    accuracy = np.mean(predictions == y_train)\n",
    "    loss = np.mean((predictions - y_train) ** 2)\n",
    "    print(f'Iteration {_+1}, Accuracy: {accuracy:.2f}, Loss: {loss:.2f}')\n",
    "\n",
    "# Save the trained model\n",
    "np.save('weights.npy', weights)\n",
    "np.save('bias.npy', bias)\n",
    "\n",
    "# Load validation data\n",
    "X_val, y_val = [], []\n",
    "for file in os.listdir(valid_directory):\n",
    "    img_path = os.path.join(valid_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_val.append(img)\n",
    "        y_val.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Load the trained model\n",
    "weights = np.load('weights.npy')\n",
    "bias = np.load('bias.npy')\n",
    "\n",
    "# Make predictions on validation set\n",
    "predictions = np.where(np.dot(X_val, weights) + bias >= 0, 1, -1)\n",
    "val_accuracy = np.mean(predictions == y_val)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test = [], []\n",
    "for file in os.listdir(test_directory):\n",
    "    img_path = os.path.join(test_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_test.append(img)\n",
    "        y_test.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Make predictions on testing set\n",
    "predictions = np.where(np.dot(X_test, weights) + bias >= 0, 1, -1)\n",
    "test_accuracy = np.mean(predictions == y_test)\n",
    "print(f'Testing Accuracy: {test_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b12bab03-e11b-416f-a804-29a0160d1a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9636 - loss: 0.1222 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.4354e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3708e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4507e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2058e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.3848e-10 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.9438e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.4624e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.4305e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8837e-09 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "## Multi Layer Perceptron\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Paths to the folders\n",
    "base_directory = '/home/pooja-sile/Desktop/2_folder/'\n",
    "train_directory = os.path.join(base_directory, 'Training')\n",
    "valid_directory = os.path.join(base_directory, 'Validation')\n",
    "test_directory = os.path.join(base_directory, 'Testing')\n",
    "\n",
    "# Load training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for file in os.listdir(train_directory):\n",
    "    img_path = os.path.join(train_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_train.append(img)\n",
    "        y_train.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Load validation data\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for file in os.listdir(valid_directory):\n",
    "    img_path = os.path.join(valid_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_val.append(img)\n",
    "        y_val.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Load test data\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for file in os.listdir(test_directory):\n",
    "    img_path = os.path.join(test_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_test.append(img)\n",
    "        y_test.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the MLP model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(32*32*3,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # 2 classes: 0 and 1\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Print training accuracy\n",
    "print(f'Training Accuracy: {history.history[\"accuracy\"][-1]:.2f}')\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Testing Accuracy: {test_accuracy:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "391f1041-8af5-4ca8-906e-185b7fc01cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model with L2 Regularization:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9781 - loss: 0.4508 - val_accuracy: 1.0000 - val_loss: 0.2464\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2302 - val_accuracy: 1.0000 - val_loss: 0.1883\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1789 - val_accuracy: 1.0000 - val_loss: 0.1544\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1485 - val_accuracy: 1.0000 - val_loss: 0.1326\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1283 - val_accuracy: 1.0000 - val_loss: 0.1162\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1128 - val_accuracy: 1.0000 - val_loss: 0.1028\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1000 - val_accuracy: 1.0000 - val_loss: 0.0916\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0892 - val_accuracy: 1.0000 - val_loss: 0.0820\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0800 - val_accuracy: 1.0000 - val_loss: 0.0738\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0720 - val_accuracy: 1.0000 - val_loss: 0.0667\n",
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n",
      "\n",
      "Training Model with Dropout:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7321 - loss: 0.4624 - val_accuracy: 1.0000 - val_loss: 9.7127e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 9.0599e-08\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6343e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-08\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2616e-04 - val_accuracy: 1.0000 - val_loss: 4.7684e-09\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6552e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.2459e-04 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.3820e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.1447e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6655e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.3821e-05 - val_accuracy: 1.0000 - val_loss: 2.3842e-09\n",
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n",
      "\n",
      "Training Model with Batch Normalization:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5014 - loss: 0.9021 - val_accuracy: 1.0000 - val_loss: 0.3760\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 0.6800 - val_accuracy: 0.7000 - val_loss: 0.5848\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7790 - loss: 0.5416 - val_accuracy: 0.9800 - val_loss: 0.3928\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9279 - loss: 0.4611 - val_accuracy: 1.0000 - val_loss: 0.3189\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9571 - loss: 0.3963 - val_accuracy: 1.0000 - val_loss: 0.2784\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.3290 - val_accuracy: 1.0000 - val_loss: 0.2400\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2778 - val_accuracy: 1.0000 - val_loss: 0.2483\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2303 - val_accuracy: 1.0000 - val_loss: 0.2152\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1853 - val_accuracy: 1.0000 - val_loss: 0.1244\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1526 - val_accuracy: 1.0000 - val_loss: 0.1550\n",
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n",
      "\n",
      "Final results:\n",
      "L2 Regularization - Training Accuracy: 1.00, Validation Accuracy: 1.00, Testing Accuracy: 1.00\n",
      "Dropout - Training Accuracy: 1.00, Validation Accuracy: 1.00, Testing Accuracy: 1.00\n",
      "Batch Normalization - Training Accuracy: 1.00, Validation Accuracy: 1.00, Testing Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "## Regularization\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "# Paths to the folders\n",
    "base_directory = '/home/pooja-sile/Desktop/2_folder/'\n",
    "train_directory = os.path.join(base_directory, 'Training')\n",
    "valid_directory = os.path.join(base_directory, 'Validation')\n",
    "test_directory = os.path.join(base_directory, 'Testing')\n",
    "\n",
    "# Initialize data lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load training data\n",
    "for file in os.listdir(train_directory):\n",
    "    img_path = os.path.join(train_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_train.append(img)\n",
    "        y_train.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "# Load validation data\n",
    "for file in os.listdir(valid_directory):\n",
    "    img_path = os.path.join(valid_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_val.append(img)\n",
    "        y_val.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "# Load test data\n",
    "for file in os.listdir(test_directory):\n",
    "    img_path = os.path.join(test_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_test.append(img)\n",
    "        y_test.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Regularization Techniques\n",
    "results = []\n",
    "\n",
    "# Model with L2 Regularization\n",
    "print(\"\\nTraining Model with L2 Regularization:\")\n",
    "model_l2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(32*32*3,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # 2 classes: 0 and 1\n",
    "])\n",
    "model_l2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_l2 = model_l2.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "train_acc_l2 = history_l2.history['accuracy'][-1]\n",
    "val_loss_l2, val_acc_l2 = model_l2.evaluate(X_val, y_val, verbose=0)\n",
    "test_loss_l2, test_acc_l2 = model_l2.evaluate(X_test, y_test, verbose=0)\n",
    "results.append(('L2 Regularization', train_acc_l2, val_acc_l2, test_acc_l2))\n",
    "print(f'Training Accuracy: {train_acc_l2:.2f}')\n",
    "print(f'Validation Accuracy: {val_acc_l2:.2f}')\n",
    "print(f'Testing Accuracy: {test_acc_l2:.2f}')\n",
    "\n",
    "# Model with Dropout\n",
    "print(\"\\nTraining Model with Dropout:\")\n",
    "model_dropout = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(32*32*3,)),\n",
    "    Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # 2 classes: 0 and 1\n",
    "])\n",
    "model_dropout.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_dropout = model_dropout.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "train_acc_dropout = history_dropout.history['accuracy'][-1]\n",
    "val_loss_dropout, val_acc_dropout = model_dropout.evaluate(X_val, y_val, verbose=0)\n",
    "test_loss_dropout, test_acc_dropout = model_dropout.evaluate(X_test, y_test, verbose=0)\n",
    "results.append(('Dropout', train_acc_dropout, val_acc_dropout, test_acc_dropout))\n",
    "print(f'Training Accuracy: {train_acc_dropout:.2f}')\n",
    "print(f'Validation Accuracy: {val_acc_dropout:.2f}')\n",
    "print(f'Testing Accuracy: {test_acc_dropout:.2f}')\n",
    "\n",
    "# Model with Batch Normalization\n",
    "print(\"\\nTraining Model with Batch Normalization:\")\n",
    "model_batchnorm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(32*32*3,)),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # 2 classes: 0 and 1\n",
    "])\n",
    "model_batchnorm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_batchnorm = model_batchnorm.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "train_acc_batchnorm = history_batchnorm.history['accuracy'][-1]\n",
    "val_loss_batchnorm, val_acc_batchnorm = model_batchnorm.evaluate(X_val, y_val, verbose=0)\n",
    "test_loss_batchnorm, test_acc_batchnorm = model_batchnorm.evaluate(X_test, y_test, verbose=0)\n",
    "results.append(('Batch Normalization', train_acc_batchnorm, val_acc_batchnorm, test_acc_batchnorm))\n",
    "print(f'Training Accuracy: {train_acc_batchnorm:.2f}')\n",
    "print(f'Validation Accuracy: {val_acc_batchnorm:.2f}')\n",
    "print(f'Testing Accuracy: {test_acc_batchnorm:.2f}')\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal results:\")\n",
    "for method, train_acc, val_acc, test_acc in results:\n",
    "    print(f'{method} - Training Accuracy: {train_acc:.2f}, Validation Accuracy: {val_acc:.2f}, Testing Accuracy: {test_acc:.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "751b360c-39f0-48e3-8563-a3ed977d094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model with Adam Optimizer:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5026 - loss: 1.0653 - val_accuracy: 0.7200 - val_loss: 0.6042\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5564 - loss: 0.9233 - val_accuracy: 0.8800 - val_loss: 0.4518\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5722 - loss: 0.7243 - val_accuracy: 1.0000 - val_loss: 0.2911\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5660 - loss: 0.7416 - val_accuracy: 0.9800 - val_loss: 0.3593\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6655 - loss: 0.5871 - val_accuracy: 0.9800 - val_loss: 0.4005\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7347 - loss: 0.5230 - val_accuracy: 1.0000 - val_loss: 0.3980\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7693 - loss: 0.4494 - val_accuracy: 0.9600 - val_loss: 0.3863\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7919 - loss: 0.4222 - val_accuracy: 0.8800 - val_loss: 0.4760\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8384 - loss: 0.3702 - val_accuracy: 0.9800 - val_loss: 0.3921\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8749 - loss: 0.3133 - val_accuracy: 0.9800 - val_loss: 0.3191\n",
      "Training Accuracy: 0.87\n",
      "Validation Accuracy: 0.98\n",
      "Testing Accuracy: 0.96\n",
      "\n",
      "Training Model with SGD Optimizer:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5233 - loss: 0.9987 - val_accuracy: 0.4800 - val_loss: 0.7122\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 0.7589 - val_accuracy: 0.5000 - val_loss: 0.7125\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6455 - loss: 0.7072 - val_accuracy: 0.9000 - val_loss: 0.5386\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.5796 - val_accuracy: 1.0000 - val_loss: 0.3553\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4995 - val_accuracy: 1.0000 - val_loss: 0.2372\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.4477 - val_accuracy: 1.0000 - val_loss: 0.2444\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.4232 - val_accuracy: 1.0000 - val_loss: 0.1824\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 0.3595 - val_accuracy: 1.0000 - val_loss: 0.1804\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8618 - loss: 0.3342 - val_accuracy: 1.0000 - val_loss: 0.1658\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.2623 - val_accuracy: 1.0000 - val_loss: 0.1548\n",
      "Training Accuracy: 0.92\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n",
      "\n",
      "Training Model with RMSprop Optimizer:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5384 - loss: 0.9680 - val_accuracy: 0.9400 - val_loss: 0.4249\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5840 - loss: 0.8178 - val_accuracy: 0.9600 - val_loss: 0.4071\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6432 - loss: 0.7314 - val_accuracy: 0.8600 - val_loss: 0.3812\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6322 - loss: 0.6838 - val_accuracy: 1.0000 - val_loss: 0.3247\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7194 - loss: 0.5709 - val_accuracy: 0.9400 - val_loss: 0.3170\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7797 - loss: 0.4762 - val_accuracy: 0.9200 - val_loss: 0.4350\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.3986 - val_accuracy: 1.0000 - val_loss: 0.2276\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.4003 - val_accuracy: 1.0000 - val_loss: 0.1766\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9009 - loss: 0.2955 - val_accuracy: 1.0000 - val_loss: 0.2046\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.2613 - val_accuracy: 1.0000 - val_loss: 0.0871\n",
      "Training Accuracy: 0.93\n",
      "Validation Accuracy: 1.00\n",
      "Testing Accuracy: 1.00\n",
      "\n",
      "Training Model with Adagrad Optimizer:\n",
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5214 - loss: 1.1540 - val_accuracy: 0.7400 - val_loss: 0.6030\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 1.1026 - val_accuracy: 0.6400 - val_loss: 0.6472\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5301 - loss: 1.0546 - val_accuracy: 0.5000 - val_loss: 0.7058\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5205 - loss: 1.0575 - val_accuracy: 0.3600 - val_loss: 0.7631\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5216 - loss: 1.1101 - val_accuracy: 0.3000 - val_loss: 0.7615\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5549 - loss: 0.9692 - val_accuracy: 0.3600 - val_loss: 0.7496\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5591 - loss: 1.0177 - val_accuracy: 0.4000 - val_loss: 0.7362\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5412 - loss: 1.0171 - val_accuracy: 0.6000 - val_loss: 0.6477\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5996 - loss: 0.8588 - val_accuracy: 0.6200 - val_loss: 0.6405\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5611 - loss: 0.9907 - val_accuracy: 0.6800 - val_loss: 0.6272\n",
      "Training Accuracy: 0.55\n",
      "Validation Accuracy: 0.68\n",
      "Testing Accuracy: 0.60\n",
      "\n",
      "Final results:\n",
      "Adam - Training Accuracy: 0.87, Validation Accuracy: 0.98, Testing Accuracy: 0.96\n",
      "SGD - Training Accuracy: 0.92, Validation Accuracy: 1.00, Testing Accuracy: 1.00\n",
      "RMSprop - Training Accuracy: 0.93, Validation Accuracy: 1.00, Testing Accuracy: 1.00\n",
      "Adagrad - Training Accuracy: 0.55, Validation Accuracy: 0.68, Testing Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "## Optimizers\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "\n",
    "# Paths to the folders\n",
    "base_directory = '/home/pooja-sile/Desktop/2_folder/'\n",
    "train_directory = os.path.join(base_directory, 'Training')\n",
    "valid_directory = os.path.join(base_directory, 'Validation')\n",
    "test_directory = os.path.join(base_directory, 'Testing')\n",
    "\n",
    "# Initialize data lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Load training data\n",
    "for file in os.listdir(train_directory):\n",
    "    img_path = os.path.join(train_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_train.append(img)\n",
    "        y_train.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "# Load validation data\n",
    "for file in os.listdir(valid_directory):\n",
    "    img_path = os.path.join(valid_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_val.append(img)\n",
    "        y_val.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "# Load test data\n",
    "for file in os.listdir(test_directory):\n",
    "    img_path = os.path.join(test_directory, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (32, 32))  # Resize the image\n",
    "        img = img.astype('float32') / 255.0  # Normalize the image\n",
    "        img = img.flatten()  # Flatten the image into a 1D array\n",
    "        X_test.append(img)\n",
    "        y_test.append(1)  # Assign class label 1\n",
    "    else:\n",
    "        print(f\"Error reading file {file}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define different optimizers\n",
    "optimizers = {\n",
    "    'Adam': tf.keras.optimizers.Adam(),\n",
    "    'SGD': tf.keras.optimizers.SGD(),\n",
    "    'RMSprop': tf.keras.optimizers.RMSprop(),\n",
    "    'Adagrad': tf.keras.optimizers.Adagrad(),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over each optimizer\n",
    "for name, optimizer in optimizers.items():\n",
    "    print(f\"\\nTraining Model with {name} Optimizer:\")\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(32*32*3,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')  # 2 classes: 0 and 1\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_acc = history.history['accuracy'][-1]\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Store results\n",
    "    results.append((name, train_acc, val_acc, test_acc))\n",
    "    print(f'Training Accuracy: {train_acc:.2f}')\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}')\n",
    "    print(f'Testing Accuracy: {test_acc:.2f}')\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal results:\")\n",
    "for name, train_acc, val_acc, test_acc in results:\n",
    "    print(f'{name} - Training Accuracy: {train_acc:.2f}, Validation Accuracy: {val_acc:.2f}, Testing Accuracy: {test_acc:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e16af-ca25-4b72-809c-375320490443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
